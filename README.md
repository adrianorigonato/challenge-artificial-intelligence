# Acesse: https://challenge-ozlg.onrender.com/ para testar. (Obs.: aguarde de 30 a 80 segundos atÃ© terminar de carregar o deploy)

**Estrutura do Projeto**
```
/
â”œâ”€â”€ app.py                     # App FastAPI principal
â”œâ”€â”€ chunking.py               # Split de texto, embeddings e busca vetorial
â”œâ”€â”€ config.py                 # ConfiguraÃ§Ã£o de APIs e variÃ¡veis de ambiente
â”œâ”€â”€ content_generation.py     # GeraÃ§Ã£o de conteÃºdos personalizados
â”œâ”€â”€ conversation.py           # LÃ³gica de conversa para anÃ¡lise
â”œâ”€â”€ conversation_analysis.py  # AvaliaÃ§Ã£o pedagÃ³gica da conversa
â”œâ”€â”€ db.py                     # ConexÃ£o e schema do banco
â”œâ”€â”€ extract.py                # IngestÃ£o e extraÃ§Ã£o multimÃ­dia
â”œâ”€â”€ orchestrator.py           # Fluxo completo RAG + anÃ¡lise + geraÃ§Ã£o
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html            # Interface da aplicaÃ§Ã£o :contentReference[oaicite:0]{index=0}
    â””â”€â”€ main.js               # LÃ³gica de UI/UX no navegador :contentReference[oaicite:1]{index=1}

```

---

**Como Funciona**

### 1. IngestÃ£o de arquivos

O usuÃ¡rio pode enviar:

- PDF  
- TXT  
- JSON  
- Ãudio (mp3, wav)  
- VÃ­deo (mp4, mov, webm...)  
- Imagens (png, jpg, webp...)

O sistema:

- Extrai texto (OCR, transcriÃ§Ã£o ou descriÃ§Ã£o de imagem)  
- Chunkifica o conteÃºdo (200â€“400 palavras com overlap)  
- Gera embeddings via OpenRouter  
- Armazena os chunks em Postgres com pgvector  

---

### 2. Chat com RAG

Cada mensagem Ã©:

- Processada com busca vetorial  
- Contextualizada com os chunks mais relevantes  
- Respondida por modelo Groq, restrito ao contexto  

---

### 3. AnÃ¡lise pedagÃ³gica

A conversa Ã© analisada por um modelo Groq que identifica:

- Subtemas  
- NÃ­vel do usuÃ¡rio: bÃ¡sico, intermediÃ¡rio, avanÃ§ado, domina  
- Justificativa  

---

### 4. GeraÃ§Ã£o de conteÃºdos personalizados

Para os subtemas com menor domÃ­nio, o sistema gera:

- Roteiros de vÃ­deo  
- Roteiros de Ã¡udio  
- Textos explicativos  

Baseado somente nos trechos da base ingerida.

---

**Como Executar**

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seuusuario/rag-learning-web.git
cd rag-learning-web
```

### 2. Crie um ambiente virtual
```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

### 3. Instale as dependÃªncias
```bash
pip install -r requirements.txt
```

### 4. Configure variÃ¡veis de ambiente

Crie um arquivo `.env` com:

```bash
DATABASE_URL=postgresql://user:password@localhost:5432/database
OPENROUTER_API_KEY=...
GROQ_API_KEY=...
```

### 5. Execute o servidor
```bash
uvicorn app:app --reload
```

Acesse em:  
**http://localhost:8000**

---

**Endpoints Principais**

### POST `/api/ingest`
Envia arquivos para ingestÃ£o vetorial.

### POST `/api/conversation/start`
Cria uma nova conversa.

### POST `/api/conversation/chat`
Envia mensagem para o chat com RAG.

### POST `/api/conversation/{id}/analyze-and-generate`
Gera conteÃºdos de estudo personalizados.

---

ğŸ¨ **Interface**

A UI possui trÃªs abas:

**Chat**
- Conversa guiada pelo assistente  
- Escolha de formato de conteÃºdo preferido  
- Mensagens estilo â€œbubble chatâ€

**Estudar**
- Exibe somente os conteÃºdos gerados  
- RenderizaÃ§Ã£o automÃ¡tica ao trocar de aba  
- Cacheamento inteligente para evitar recomputaÃ§Ã£o

**IngestÃ£o**
- Upload de arquivos  
- Feedback sobre chunks inseridos  
